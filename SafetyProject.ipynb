{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU5DjPD64gbwya1M3215aJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brotheramin/MachineLearning/blob/main/SafetyProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWtx3Ud4eCgg",
        "outputId": "6d11a0b4-aa1e-4533-c7e4-146a27965dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sizes -> Train: 273, Val: 91, Test: 92\n",
            "Class counts (train): [213  60]\n",
            "Class counts (val)  : [65 26]\n",
            "Class counts (test) : [65 27]\n",
            "\n",
            "Chosen threshold (max F1 on validation): 0.268\n",
            "\n",
            "=== VALIDATION METRICS ===\n",
            "Accuracy  : 0.923\n",
            "Precision : 0.828\n",
            "Recall    : 0.923\n",
            "F1 Score  : 0.873\n",
            "PR-AUC    : 0.863\n",
            "ROC-AUC   : 0.9337278106508876\n",
            "Confusion : [[60, 5], [2, 24]]\n",
            "\n",
            "=== TEST METRICS ===\n",
            "Threshold : 0.268\n",
            "Accuracy  : 0.924\n",
            "Precision : 0.812\n",
            "Recall    : 0.963\n",
            "F1 Score  : 0.881\n",
            "PR-AUC    : 0.923\n",
            "ROC-AUC   : 0.9695156695156695\n",
            "Confusion : [[59, 6], [1, 26]]\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Process Failure (off-spec > 15 ppm) classification on the BALANCED dataset.\n",
        "\n",
        "- File: level_transmitter_oilywater_dataset_456_balanced.csv\n",
        "- Split: time-aware 60% train / 20% val / 20% test\n",
        "- Model: RandomForestClassifier (no SMOTE required)\n",
        "- Threshold: chosen on validation by maximizing F1\n",
        "- Outputs: clean printed metrics + PR/ROC curves + feature importances\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    confusion_matrix, precision_recall_curve, average_precision_score, roc_curve\n",
        ")\n",
        "\n",
        "DATA_PATH = \"level_transmitter_oilywater_dataset_456_balanced.csv\"\n",
        "OUT_DIR = Path(\"outputs_balanced_rf\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "FEATURES = [\n",
        "    \"influent_oil_ppm\",\"turbidity_ntu\",\"flow_l_min\",\"temperature_c\",\"pH\",\n",
        "    \"ec_current_a\",\"ec_voltage_v\",\"demulsifier_ml_min\",\n",
        "    \"interface_level_pct\",\"pressure_bar\",\"foam_index\",\"fouling_index\",\n",
        "    \"sensor_drift_pct\",\"lt_signal_pct\",\"lt_health_score\"\n",
        "]\n",
        "LABEL = \"offspec_gt15ppm\"  # 1 if outlet > 15 ppm\n",
        "\n",
        "def pick_threshold_by_f1(y_val, proba_val):\n",
        "    \"\"\"Pick threshold that maximizes F1 on validation probabilities.\"\"\"\n",
        "    prec, rec, thr = precision_recall_curve(y_val, proba_val)\n",
        "    # precision_recall_curve returns len(thr) = len(prec) - 1\n",
        "    f1 = np.where((prec+rec) > 0, 2*prec*rec/(prec+rec), 0)\n",
        "    if len(thr) == 0:\n",
        "        return 0.5  # degenerate case; shouldn't happen on balanced data\n",
        "    best_idx = int(np.nanargmax(f1[:-1])) if len(f1) > 1 else 0\n",
        "    return float(thr[best_idx])\n",
        "\n",
        "def eval_split(y_true, proba, threshold):\n",
        "    y_pred = (proba >= threshold).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    ap = average_precision_score(y_true, proba)\n",
        "    rocauc = roc_auc_score(y_true, proba) if len(np.unique(y_true)) > 1 else None\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    return acc, prec, rec, f1, ap, rocauc, cm\n",
        "\n",
        "def main():\n",
        "    # ----- Load & order by time -----\n",
        "    df = pd.read_csv(DATA_PATH, parse_dates=[\"timestamp\"]).sort_values(\"timestamp\").reset_index(drop=True)\n",
        "\n",
        "    X = df[FEATURES].values\n",
        "    y = df[LABEL].astype(int).values\n",
        "\n",
        "    n = len(df)\n",
        "    i_tr = int(0.6*n)\n",
        "    i_va = int(0.8*n)\n",
        "\n",
        "    X_tr, y_tr = X[:i_tr], y[:i_tr]\n",
        "    X_va, y_va = X[i_tr:i_va], y[i_tr:i_va]\n",
        "    X_te, y_te = X[i_va:], y[i_va:]\n",
        "\n",
        "    print(f\"Sizes -> Train: {len(y_tr)}, Val: {len(y_va)}, Test: {len(y_te)}\")\n",
        "    print(\"Class counts (train):\", np.bincount(y_tr))\n",
        "    print(\"Class counts (val)  :\", np.bincount(y_va))\n",
        "    print(\"Class counts (test) :\", np.bincount(y_te))\n",
        "\n",
        "    # ----- Train RandomForest -----\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=600,\n",
        "        random_state=42,\n",
        "        class_weight=None  # data is already balanced\n",
        "    )\n",
        "    rf.fit(X_tr, y_tr)\n",
        "\n",
        "    # ----- Threshold on VALIDATION -----\n",
        "    proba_va = rf.predict_proba(X_va)[:, 1]\n",
        "    thr = pick_threshold_by_f1(y_va, proba_va)\n",
        "    print(f\"\\nChosen threshold (max F1 on validation): {thr:.3f}\")\n",
        "\n",
        "    # ----- Evaluate on VAL -----\n",
        "    acc_v, prec_v, rec_v, f1_v, ap_v, roc_v, cm_v = eval_split(y_va, proba_va, thr)\n",
        "    print(\"\\n=== VALIDATION METRICS ===\")\n",
        "    print(f\"Accuracy  : {acc_v:.3f}\")\n",
        "    print(f\"Precision : {prec_v:.3f}\")\n",
        "    print(f\"Recall    : {rec_v:.3f}\")\n",
        "    print(f\"F1 Score  : {f1_v:.3f}\")\n",
        "    print(f\"PR-AUC    : {ap_v:.3f}\")\n",
        "    print(f\"ROC-AUC   : {roc_v}\")\n",
        "    print(f\"Confusion : {cm_v.tolist()}\")\n",
        "\n",
        "    # ----- Evaluate on TEST -----\n",
        "    proba_te = rf.predict_proba(X_te)[:, 1]\n",
        "    acc, prec, rec, f1, ap, rocauc, cm = eval_split(y_te, proba_te, thr)\n",
        "\n",
        "    print(\"\\n=== TEST METRICS ===\")\n",
        "    print(f\"Threshold : {thr:.3f}\")\n",
        "    print(f\"Accuracy  : {acc:.3f}\")\n",
        "    print(f\"Precision : {prec:.3f}\")\n",
        "    print(f\"Recall    : {rec:.3f}\")\n",
        "    print(f\"F1 Score  : {f1:.3f}\")\n",
        "    print(f\"PR-AUC    : {ap:.3f}\")\n",
        "    print(f\"ROC-AUC   : {rocauc}\")\n",
        "    print(f\"Confusion : {cm.tolist()}\")\n",
        "\n",
        "    # ----- PR curve (Test) -----\n",
        "    prec_te, rec_te, _ = precision_recall_curve(y_te, proba_te)\n",
        "    plt.figure()\n",
        "    plt.plot(rec_te, prec_te)\n",
        "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Balanced RF – Precision-Recall (Test)\")\n",
        "    plt.grid(True); plt.tight_layout()\n",
        "    plt.savefig(OUT_DIR / \"pr_curve_test.png\"); plt.close()\n",
        "\n",
        "    # ----- ROC curve (Test) -----\n",
        "    if len(np.unique(y_te)) > 1:\n",
        "        fpr, tpr, _ = roc_curve(y_te, proba_te)\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')\n",
        "        plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
        "        plt.title(\"Balanced RF – ROC (Test)\")\n",
        "        plt.grid(True); plt.tight_layout()\n",
        "        plt.savefig(OUT_DIR / \"roc_curve_test.png\"); plt.close()\n",
        "\n",
        "    # ----- Feature importances -----\n",
        "    importances = rf.feature_importances_\n",
        "    idx = np.argsort(importances)[::-1][:10]\n",
        "    plt.figure()\n",
        "    plt.bar(range(len(idx)), importances[idx])\n",
        "    plt.xticks(range(len(idx)), [FEATURES[i] for i in idx], rotation=45, ha='right')\n",
        "    plt.ylabel(\"Importance\"); plt.title(\"Balanced RF – Top Features\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUT_DIR / \"feature_importances.png\"); plt.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}