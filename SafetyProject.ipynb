{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH0EOviwBmLm1sdY95hooC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brotheramin/MachineLearning/blob/main/SafetyProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfm1qCANzwkL",
        "outputId": "593fdcab-2c61-41a0-a226-0f8881641d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Original class distribution: Counter({0: 216, 1: 28, 3: 24, 2: 24, 4: 5})\n",
            "Resampled class distribution: Counter({0: 216, 3: 50, 2: 50, 1: 50, 4: 50})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:09:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.91      0.88       100\n",
            "           1       0.43      0.25      0.32        12\n",
            "           2       0.33      0.14      0.20         7\n",
            "           3       0.11      0.17      0.13         6\n",
            "           4       0.50      0.33      0.40         3\n",
            "\n",
            "    accuracy                           0.76       128\n",
            "   macro avg       0.44      0.36      0.39       128\n",
            "weighted avg       0.74      0.76      0.74       128\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install xgboost if not already installed\n",
        "!pip install xgboost\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('IHMStefanini_industrial_safety_and_health_database_with_accidents_description.csv')\n",
        "\n",
        "# Data cleaning: Drop unnecessary columns and extract date-related features\n",
        "df_clean = df.drop(columns=['Unnamed: 0'])  # Dropping the index column if it exists\n",
        "\n",
        "# Convert the date to datetime and extract Year, Month, and Day\n",
        "df_clean['Data'] = pd.to_datetime(df_clean['Data'])\n",
        "df_clean['Year'] = df_clean['Data'].dt.year\n",
        "df_clean['Month'] = df_clean['Data'].dt.month\n",
        "df_clean['Day'] = df_clean['Data'].dt.day\n",
        "\n",
        "# Drop the original 'Data' column as it's no longer needed\n",
        "df_clean = df_clean.drop(columns=['Data'])\n",
        "\n",
        "# Label Encoding for categorical features\n",
        "columns_to_encode = ['Countries', 'Local', 'Industry Sector', 'Accident Level',\n",
        "                     'Potential Accident Level', 'Genre', 'Employee or Third Party',\n",
        "                     'Critical Risk']\n",
        "\n",
        "# Apply Label Encoding\n",
        "label_encoders = {}\n",
        "for col in columns_to_encode:\n",
        "    le = LabelEncoder()\n",
        "    df_clean[col] = le.fit_transform(df_clean[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Vectorize the 'Description' text field using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=100)\n",
        "X_text = tfidf.fit_transform(df_clean['Description']).toarray()\n",
        "\n",
        "# Combine the text features with the rest of the dataset (excluding 'Description' column)\n",
        "X = pd.concat([df_clean.drop(columns=['Description', 'Accident Level']),\n",
        "               pd.DataFrame(X_text, columns=[f'tfidf_{i}' for i in range(X_text.shape[1])])], axis=1)\n",
        "y = df_clean['Accident Level']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Display class distribution before resampling\n",
        "print(\"Original class distribution:\", Counter(y_train))\n",
        "\n",
        "# Apply SMOTE with a custom sampling strategy and k_neighbors=1\n",
        "smote = SMOTE(random_state=42, sampling_strategy={1: 50, 2: 50, 3: 50, 4: 50}, k_neighbors=1)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Display class distribution after SMOTE\n",
        "print(\"Resampled class distribution:\", Counter(y_train_resampled))\n",
        "\n",
        "# Train an XGBoost classifier with tuned scale_pos_weight\n",
        "xgb_model = XGBClassifier(random_state=42, scale_pos_weight=1, n_estimators=200, learning_rate=0.05, max_depth=5)\n",
        "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ]
    }
  ]
}