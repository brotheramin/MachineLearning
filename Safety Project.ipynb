{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brotheramin/MachineLearning/blob/main/Safety%20Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('IHMStefanini_industrial_safety_and_health_database_with_accidents_description.csv')\n",
        "\n",
        "# Data cleaning: Drop unnecessary columns and extract date-related features\n",
        "df_clean = df.drop(columns=['Unnamed: 0'])  # Dropping the index column if it exists\n",
        "\n",
        "# Convert the date to datetime and extract Year, Month, and Day\n",
        "df_clean['Data'] = pd.to_datetime(df_clean['Data'])\n",
        "df_clean['Year'] = df_clean['Data'].dt.year\n",
        "df_clean['Month'] = df_clean['Data'].dt.month\n",
        "df_clean['Day'] = df_clean['Data'].dt.day\n",
        "\n",
        "# Drop the original 'Data' column as it's no longer needed\n",
        "df_clean = df_clean.drop(columns=['Data'])\n",
        "\n",
        "# Label Encoding for categorical features\n",
        "columns_to_encode = ['Countries', 'Local', 'Industry Sector', 'Accident Level',\n",
        "                     'Potential Accident Level', 'Genre', 'Employee or Third Party',\n",
        "                     'Critical Risk']\n",
        "\n",
        "# Apply Label Encoding\n",
        "label_encoders = {}\n",
        "for col in columns_to_encode:\n",
        "    le = LabelEncoder()\n",
        "    df_clean[col] = le.fit_transform(df_clean[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Vectorize the 'Description' text field using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=100)\n",
        "X_text = tfidf.fit_transform(df_clean['Description']).toarray()\n",
        "\n",
        "# Combine the text features with the rest of the dataset (excluding 'Description' column)\n",
        "X = pd.concat([df_clean.drop(columns=['Description', 'Accident Level']),\n",
        "               pd.DataFrame(X_text, columns=[f'tfidf_{i}' for i in range(X_text.shape[1])])], axis=1)\n",
        "y = df_clean['Accident Level']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = rf_model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ],
      "metadata": {
        "id": "BksidQBngsXa",
        "outputId": "0e61a803-f603-46b5-c7fe-2853fd15145b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      1.00      0.88       100\n",
            "           1       0.00      0.00      0.00        12\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.00      0.00      0.00         6\n",
            "           4       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.78       128\n",
            "   macro avg       0.16      0.20      0.18       128\n",
            "weighted avg       0.61      0.78      0.69       128\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('IHMStefanini_industrial_safety_and_health_database_with_accidents_description.csv')\n",
        "\n",
        "# Data cleaning: Drop unnecessary columns and extract date-related features\n",
        "df_clean = df.drop(columns=['Unnamed: 0'])  # Dropping the index column if it exists\n",
        "\n",
        "# Convert the date to datetime and extract Year, Month, and Day\n",
        "df_clean['Data'] = pd.to_datetime(df_clean['Data'])\n",
        "df_clean['Year'] = df_clean['Data'].dt.year\n",
        "df_clean['Month'] = df_clean['Data'].dt.month\n",
        "df_clean['Day'] = df_clean['Data'].dt.day\n",
        "\n",
        "# Drop the original 'Data' column as it's no longer needed\n",
        "df_clean = df_clean.drop(columns=['Data'])\n",
        "\n",
        "# Label Encoding for categorical features\n",
        "columns_to_encode = ['Countries', 'Local', 'Industry Sector', 'Accident Level',\n",
        "                     'Potential Accident Level', 'Genre', 'Employee or Third Party',\n",
        "                     'Critical Risk']\n",
        "\n",
        "# Apply Label Encoding\n",
        "label_encoders = {}\n",
        "for col in columns_to_encode:\n",
        "    le = LabelEncoder()\n",
        "    df_clean[col] = le.fit_transform(df_clean[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Vectorize the 'Description' text field using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=100)\n",
        "X_text = tfidf.fit_transform(df_clean['Description']).toarray()\n",
        "\n",
        "# Combine the text features with the rest of the dataset (excluding 'Description' column)\n",
        "X = pd.concat([df_clean.drop(columns=['Description', 'Accident Level']),\n",
        "               pd.DataFrame(X_text, columns=[f'tfidf_{i}' for i in range(X_text.shape[1])])], axis=1)\n",
        "y = df_clean['Accident Level']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Handle class imbalance using RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train a Random Forest classifier with balanced classes\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = rf_model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ],
      "metadata": {
        "id": "U806m4vlhf-7",
        "outputId": "f64c3423-cc43-4819-8746-587ff8b4e593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.99      0.88       100\n",
            "           1       0.00      0.00      0.00        12\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.00      0.00      0.00         6\n",
            "           4       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.77       128\n",
            "   macro avg       0.16      0.20      0.18       128\n",
            "weighted avg       0.61      0.77      0.68       128\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install xgboost if not already installed\n",
        "!pip install xgboost\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('IHMStefanini_industrial_safety_and_health_database_with_accidents_description.csv')\n",
        "\n",
        "# Data cleaning: Drop unnecessary columns and extract date-related features\n",
        "df_clean = df.drop(columns=['Unnamed: 0'])  # Dropping the index column if it exists\n",
        "\n",
        "# Convert the date to datetime and extract Year, Month, and Day\n",
        "df_clean['Data'] = pd.to_datetime(df_clean['Data'])\n",
        "df_clean['Year'] = df_clean['Data'].dt.year\n",
        "df_clean['Month'] = df_clean['Data'].dt.month\n",
        "df_clean['Day'] = df_clean['Data'].dt.day\n",
        "\n",
        "# Drop the original 'Data' column as it's no longer needed\n",
        "df_clean = df_clean.drop(columns=['Data'])\n",
        "\n",
        "# Label Encoding for categorical features\n",
        "columns_to_encode = ['Countries', 'Local', 'Industry Sector', 'Accident Level',\n",
        "                     'Potential Accident Level', 'Genre', 'Employee or Third Party',\n",
        "                     'Critical Risk']\n",
        "\n",
        "# Apply Label Encoding\n",
        "label_encoders = {}\n",
        "for col in columns_to_encode:\n",
        "    le = LabelEncoder()\n",
        "    df_clean[col] = le.fit_transform(df_clean[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Vectorize the 'Description' text field using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=100)\n",
        "X_text = tfidf.fit_transform(df_clean['Description']).toarray()\n",
        "\n",
        "# Combine the text features with the rest of the dataset (excluding 'Description' column)\n",
        "X = pd.concat([df_clean.drop(columns=['Description', 'Accident Level']),\n",
        "               pd.DataFrame(X_text, columns=[f'tfidf_{i}' for i in range(X_text.shape[1])])], axis=1)\n",
        "y = df_clean['Accident Level']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply SMOTE to balance the training set with k_neighbors set to 3\n",
        "smote = SMOTE(random_state=42, k_neighbors=3)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train an XGBoost classifier with class weighting\n",
        "xgb_model = XGBClassifier(random_state=42, scale_pos_weight=1)\n",
        "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ],
      "metadata": {
        "id": "1bWtNmEDh-5a",
        "outputId": "8bab15e0-b7c9-4126-8773-bd350be11684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.22.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [13:37:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.86       100\n",
            "           1       0.00      0.00      0.00        12\n",
            "           2       0.20      0.14      0.17         7\n",
            "           3       0.18      0.33      0.24         6\n",
            "           4       0.50      0.33      0.40         3\n",
            "\n",
            "    accuracy                           0.71       128\n",
            "   macro avg       0.35      0.34      0.33       128\n",
            "weighted avg       0.69      0.71      0.70       128\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('IHMStefanini_industrial_safety_and_health_database_with_accidents_description.csv')\n",
        "\n",
        "# Data cleaning: Drop unnecessary columns and extract date-related features\n",
        "df_clean = df.drop(columns=['Unnamed: 0'])  # Dropping the index column if it exists\n",
        "\n",
        "# Convert the date to datetime and extract Year, Month, and Day\n",
        "df_clean['Data'] = pd.to_datetime(df_clean['Data'])\n",
        "df_clean['Year'] = df_clean['Data'].dt.year\n",
        "df_clean['Month'] = df_clean['Data'].dt.month\n",
        "df_clean['Day'] = df_clean['Data'].dt.day\n",
        "\n",
        "# Drop the original 'Data' column as it's no longer needed\n",
        "df_clean = df_clean.drop(columns=['Data'])\n",
        "\n",
        "# Label Encoding for categorical features\n",
        "columns_to_encode = ['Countries', 'Local', 'Industry Sector', 'Accident Level',\n",
        "                     'Potential Accident Level', 'Genre', 'Employee or Third Party',\n",
        "                     'Critical Risk']\n",
        "\n",
        "# Apply Label Encoding\n",
        "label_encoders = {}\n",
        "for col in columns_to_encode:\n",
        "    le = LabelEncoder()\n",
        "    df_clean[col] = le.fit_transform(df_clean[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Vectorize the 'Description' text field using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=100)\n",
        "X_text = tfidf.fit_transform(df_clean['Description']).toarray()\n",
        "\n",
        "# Combine the text features with the rest of the dataset (excluding 'Description' column)\n",
        "X = pd.concat([df_clean.drop(columns=['Description', 'Accident Level']),\n",
        "               pd.DataFrame(X_text, columns=[f'tfidf_{i}' for i in range(X_text.shape[1])])], axis=1)\n",
        "y = df_clean['Accident Level']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Apply SMOTE to balance the training set with k_neighbors set to 3\n",
        "smote = SMOTE(random_state=42, k_neighbors=3)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = rf_model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ],
      "metadata": {
        "id": "45RRk_ytidvT",
        "outputId": "a5443f5f-000e-448f-b020-91984afb57aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.95      0.85       100\n",
            "           1       0.00      0.00      0.00        12\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.00      0.00      0.00         6\n",
            "           4       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.74       128\n",
            "   macro avg       0.15      0.19      0.17       128\n",
            "weighted avg       0.60      0.74      0.67       128\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original class distribution:\", Counter(y_train))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "63oViAYDkDnt",
        "outputId": "de9b24fb-e848-48b3-8f0c-5592119d5484",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution: Counter({0: 216, 1: 28, 3: 24, 2: 24, 4: 5})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42, sampling_strategy={1: 50, 2: 50, 3: 50, 4: 50}, k_neighbors=2)"
      ],
      "metadata": {
        "id": "D83b751ElFxy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the current class distribution\n",
        "class_counts = Counter(y_train)\n",
        "\n",
        "# Set the target number for each class to be the minimum of:\n",
        "# a) 50 (your original target)\n",
        "# b) The current count for that class\n",
        "# c) The minimum count among all classes\n",
        "min_count = min(class_counts.values())\n",
        "sampling_strategy = {cls: min(count, 50, min_count) for cls, count in class_counts.items()}\n",
        "\n",
        "smote = SMOTE(random_state=42, sampling_strategy=sampling_strategy, k_neighbors=2)"
      ],
      "metadata": {
        "id": "RYhODA82lMzt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Display class distribution before resampling\n",
        "print(\"Original class distribution:\", Counter(y_train))\n",
        "\n",
        "# Get the current class distribution\n",
        "class_counts = Counter(y_train)\n",
        "\n",
        "# Set the target number for each class\n",
        "max_count = max(class_counts.values())\n",
        "sampling_strategy = {cls: max(count, min(max_count, 50)) for cls, count in class_counts.items()}\n",
        "\n",
        "# Use RandomOverSampler\n",
        "ros = RandomOverSampler(random_state=42, sampling_strategy=sampling_strategy)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "# Display class distribution after resampling\n",
        "print(\"Resampled class distribution:\", Counter(y_train_resampled))"
      ],
      "metadata": {
        "id": "wezji7JnlPnS",
        "outputId": "7ad2e980-da84-4dc3-8a1b-023c3119308a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original class distribution: Counter({0: 216, 1: 28, 3: 24, 2: 24, 4: 5})\n",
            "Resampled class distribution: Counter({0: 216, 3: 50, 2: 50, 1: 50, 4: 50})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(random_state=42, scale_pos_weight=1, n_estimators=200, learning_rate=0.05, max_depth=5)\n",
        "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ],
      "metadata": {
        "id": "Md3oE-molS5k",
        "outputId": "de0df791-0e78-4608-d97c-c819d4c795c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [13:47:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.96      0.90       100\n",
            "           1       0.25      0.08      0.12        12\n",
            "           2       0.00      0.00      0.00         7\n",
            "           3       0.17      0.17      0.17         6\n",
            "           4       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.78       128\n",
            "   macro avg       0.45      0.38      0.40       128\n",
            "weighted avg       0.71      0.78      0.74       128\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}