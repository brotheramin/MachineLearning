{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNI+iSJRV/uDPI8shv93NN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brotheramin/MachineLearning/blob/main/Sahand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB8ocK3tOeH_",
        "outputId": "ed2da5cf-6a26-4893-dbe8-ffb2625ac75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Classification Metrics ===\n",
            "Accuracy : 0.9957\n",
            "\n",
            "Confusion Matrix [ [TN FP] [FN TP] ]\n",
            "[[  20   12]\n",
            " [  12 5561]]\n",
            "\n",
            "Saved classifier to: HydroTest_rf_classifier.pkl\n",
            "Saved top features to: HydroTest_rf_top_features.csv\n"
          ]
        }
      ],
      "source": [
        "# ===== Quality Classification on XF.xlsx (HydroTest or RESULT) =====\n",
        "# - Version-safe OneHotEncoder (works with old/new scikit-learn)\n",
        "# - Handles class imbalance\n",
        "# - Prints Accuracy / Precision / Recall / F1 / ROC-AUC + Confusion Matrix\n",
        "# - Saves trained model and top features\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Optional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        ")\n",
        "import joblib\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "EXCEL_PATH = \"XF.xlsx\"\n",
        "SHEET_NAME = \"Sheet2\"\n",
        "TARGET_LABEL = \"HydroTest\"      # <-- change to \"RESULT\" if you want ACC vs others\n",
        "POSITIVE_CLASS_FOR_RESULT = \"ACC\"  # used only when TARGET_LABEL == \"RESULT\"\n",
        "\n",
        "# -----------------------------\n",
        "# Version-safe OneHotEncoder\n",
        "# -----------------------------\n",
        "def make_onehot():\n",
        "    try:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True, min_frequency=0.01)\n",
        "    except TypeError:\n",
        "        try:\n",
        "            return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
        "        except TypeError:\n",
        "            try:\n",
        "                return OneHotEncoder(handle_unknown=\"ignore\", sparse=True, min_frequency=0.01)\n",
        "            except TypeError:\n",
        "                return OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
        "\n",
        "# -----------------------------\n",
        "# Load & clean\n",
        "# -----------------------------\n",
        "try:\n",
        "    df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME)\n",
        "except Exception:\n",
        "    xls = pd.ExcelFile(EXCEL_PATH)\n",
        "    df = pd.read_excel(EXCEL_PATH, sheet_name=xls.sheet_names[0])\n",
        "\n",
        "# Drop Excel artifacts + very sparse columns (>70% missing)\n",
        "drop_unnamed = [c for c in df.columns if str(c).strip().lower().startswith(\"unnamed\")]\n",
        "df.drop(columns=drop_unnamed, inplace=True, errors=\"ignore\")\n",
        "missing_frac = df.isna().mean()\n",
        "df.drop(columns=missing_frac[missing_frac > 0.70].index.tolist(), inplace=True, errors=\"ignore\")\n",
        "\n",
        "# Drop ID-like columns\n",
        "for col in [\"Counter\", \"Weld NO.\"]:\n",
        "    if col in df.columns:\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# Coerce common numeric-like columns (keep all three lines!)\n",
        "for c in [\"THK (IN)\", \"Voltage\", \"Temp\"]:\n",
        "    if c in df.columns:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "# -----------------------------\n",
        "# Target mapping\n",
        "# -----------------------------\n",
        "if TARGET_LABEL not in df.columns:\n",
        "    raise ValueError(f\"'{TARGET_LABEL}' not found in columns: {list(df.columns)}\")\n",
        "\n",
        "y_raw = df[TARGET_LABEL].astype(str)\n",
        "\n",
        "if TARGET_LABEL.lower() == \"hydrotest\":\n",
        "    # Positive = \"Pass\"\n",
        "    y = y_raw.str.strip().str.lower().eq(\"pass\").astype(int)\n",
        "else:\n",
        "    # RESULT: Positive class (ACC by default)\n",
        "    pos = POSITIVE_CLASS_FOR_RESULT.strip().upper()\n",
        "    y = y_raw.str.strip().str.upper().eq(pos).astype(int)\n",
        "\n",
        "# Keep only rows with a known target\n",
        "mask = y_raw.notna()\n",
        "X = df.loc[mask].drop(columns=[TARGET_LABEL]).copy()\n",
        "y = y.loc[mask]\n",
        "\n",
        "# -----------------------------\n",
        "# Feature selection (control one-hot width)\n",
        "# -----------------------------\n",
        "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
        "num_cols = [c for c in X.columns if c not in cat_cols]\n",
        "\n",
        "# Prefer a few known cats + any with small cardinality\n",
        "preferred_cats = [c for c in [\"Grade\", \"Sec\", \"BEND\", \"Weather\"] if c in cat_cols]\n",
        "small_cats = [c for c in cat_cols if c not in preferred_cats and X[c].nunique() <= 30]\n",
        "use_cat = list(dict.fromkeys(preferred_cats + small_cats))\n",
        "use_num = num_cols.copy()\n",
        "\n",
        "# Make sure categoricals are strings\n",
        "for c in use_cat:\n",
        "    X[c] = X[c].astype(str)\n",
        "\n",
        "X = X[use_cat + use_num]\n",
        "\n",
        "# -----------------------------\n",
        "# Train/test split (stratified to preserve class balance)\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Pipeline\n",
        "# -----------------------------\n",
        "cat_encoder = make_onehot()\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"num\", SimpleImputer(strategy=\"median\"), use_num),\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"onehot\", cat_encoder)\n",
        "    ]), use_cat),\n",
        "])\n",
        "\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=240,\n",
        "    max_depth=24,\n",
        "    min_samples_leaf=5,\n",
        "    max_features=0.7,\n",
        "    class_weight=\"balanced\",  # handle imbalance\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "pipe = Pipeline([\n",
        "    (\"preprocess\", preprocess),\n",
        "    (\"clf\", clf)\n",
        "])\n",
        "\n",
        "# -----------------------------\n",
        "# Train\n",
        "# -----------------------------\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluate (threshold 0.5)\n",
        "# -----------------------------\n",
        "proba = pipe.predict_proba(X_test)[:, 1]\n",
        "pred  = (proba >= 0.5).astype(int)\n",
        "\n",
        "acc  = accuracy_score(y_test, pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
        "try:\n",
        "    auc = roc_auc_score(y_test, proba)\n",
        "except Exception:\n",
        "    auc = float(\"nan\")\n",
        "\n",
        "print(\"=== Classification Metrics ===\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "print(\"\\nConfusion Matrix [ [TN FP] [FN TP] ]\")\n",
        "print(cm)\n",
        "\n",
        "# -----------------------------\n",
        "# Save model\n",
        "# -----------------------------\n",
        "model_path = f\"{TARGET_LABEL}_rf_classifier.pkl\"\n",
        "joblib.dump(pipe, model_path)\n",
        "print(f\"\\nSaved classifier to: {model_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Save top features\n",
        "# -----------------------------\n",
        "try:\n",
        "    pre = pipe.named_steps[\"preprocess\"]\n",
        "    est = pipe.named_steps[\"clf\"]\n",
        "    names = list(use_num)\n",
        "    try:\n",
        "        oh = pre.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "        try:\n",
        "            oh_names = oh.get_feature_names_out(use_cat).tolist()\n",
        "        except Exception:\n",
        "            oh_names = []\n",
        "            if hasattr(oh, \"categories_\"):\n",
        "                for base, cats in zip(use_cat, oh.categories_):\n",
        "                    for cat in cats:\n",
        "                        oh_names.append(f\"{base}={cat}\")\n",
        "            else:\n",
        "                for base in use_cat:\n",
        "                    oh_names.append(f\"{base}_encoded\")\n",
        "        names += oh_names\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    importances = est.feature_importances_\n",
        "    fi = (pd.DataFrame({\"feature\": names, \"importance\": importances})\n",
        "          .sort_values(\"importance\", ascending=False).head(30))\n",
        "    fi.to_csv(f\"{TARGET_LABEL}_rf_top_features.csv\", index=False)\n",
        "    print(f\"Saved top features to: {TARGET_LABEL}_rf_top_features.csv\")\n",
        "except Exception as e:\n",
        "    print(\"Feature importances skipped:\", e)\n"
      ]
    }
  ]
}