{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNsjOracd2hVbpfyFgReuxN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brotheramin/MachineLearning/blob/main/CreditCardFraud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Credit Card Fraud Detection**\n",
        "\n",
        "The dataset contains transactions made by credit cards in September 2013 by european cardholders. This dataset represents transactions that occurred in two days, where we have 492 cases of fraud out of 284,807 transactions. The dataset is highly unbalanced, the positive class (known fraudulent transactions) account for only 0.172% of all transactions.\n",
        "\n",
        "An autoencoder is used as an unsupervised model to identify irregularities that might indicate fraud. It is imperfect, but works reasonably well.\n",
        "\n",
        "The data is available on [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud)"
      ],
      "metadata": {
        "id": "foQ9N-cwDrcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x"
      ],
      "metadata": {
        "id": "kX4hGOHqD0D9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZOw23i5gDCe3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read Data**\n",
        "\n",
        "The original data set is fairly large. To reduce experiment cycle time, a subset of of the data is used here. The data is available on Kaggle, which requires login. If you are using Google Colab, you can download the zip file to your local machine and then upload it into a Google Colab notebook. Pandas can read zip files directly."
      ],
      "metadata": {
        "id": "YhJxv2k7D-CJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"creditcard.csv\")\n",
        "data = data.head(30000)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwOfj2wdEB4W",
        "outputId": "324bc2c7-b062-4778-f9f7-7e4391a7b4be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ZRqgFCDsEFX3",
        "outputId": "47e6ff8e-fd7c-476b-9b29-aaeab2c53082"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       712  1.38284715007044  -0.00637330519583678  -0.496478563762524  \\\n",
              "0  34714.0         -0.505623              0.696249            0.864695   \n",
              "1  34714.0         -1.347241              1.278883            1.380049   \n",
              "2  34715.0         -1.997486             -6.247751           -2.146480   \n",
              "3  34715.0         -0.373098              1.153177            1.436122   \n",
              "4  34716.0         -0.338448             -0.012549            1.548567   \n",
              "\n",
              "   -1.08205305225498  -0.0808830443608156  -1.15632019489055  \\\n",
              "0           1.120677             0.042565          -0.077980   \n",
              "1           0.913509             0.162013          -0.114490   \n",
              "2           0.828500            -2.484162          -0.205025   \n",
              "3           0.138901            -0.096129          -1.163653   \n",
              "4          -2.132899             0.332593           0.183520   \n",
              "\n",
              "   0.292571822610627  -0.258428163078786  1.06456613243598  ...  \\\n",
              "0           0.948634           -0.118641         -0.296673  ...   \n",
              "1           0.916754           -0.141199         -0.537024  ...   \n",
              "2           2.006526           -0.658223         -0.743316  ...   \n",
              "3           0.746219           -0.115367         -0.474063  ...   \n",
              "4           0.186680            0.020768         -1.327153  ...   \n",
              "\n",
              "   -0.449804627263864  -1.27888499555974  0.019728921381961  \\\n",
              "0            0.054431           0.398556           0.037060   \n",
              "1            0.002815           0.415186          -0.456130   \n",
              "2            1.187403          -0.648449          -1.788212   \n",
              "3           -0.236107          -0.599251           0.027593   \n",
              "4           -0.020604          -0.109244          -0.133021   \n",
              "\n",
              "   -0.525997185720502  0.561247041848369  -0.845993246118688  \\\n",
              "0            0.175790          -0.386621           -0.328350   \n",
              "1            0.137008           0.504979           -0.115927   \n",
              "2           -0.005568           0.155405           -0.220592   \n",
              "3            0.670301          -0.190295            0.050345   \n",
              "4           -0.856017          -0.334356           -0.628094   \n",
              "\n",
              "   0.0125287619204441  0.00912469017906386     1.62    0  \n",
              "0           -0.046589            -0.075340    81.40  0.0  \n",
              "1            0.314052             0.158906    88.23  0.0  \n",
              "2           -0.356211             0.307654  1800.00  0.0  \n",
              "3            0.247474             0.102719     5.36  0.0  \n",
              "4           -0.057004            -0.117696     5.00  0.0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5fe9e93-b14d-453f-9acf-cc62ee5425fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>712</th>\n",
              "      <th>1.38284715007044</th>\n",
              "      <th>-0.00637330519583678</th>\n",
              "      <th>-0.496478563762524</th>\n",
              "      <th>-1.08205305225498</th>\n",
              "      <th>-0.0808830443608156</th>\n",
              "      <th>-1.15632019489055</th>\n",
              "      <th>0.292571822610627</th>\n",
              "      <th>-0.258428163078786</th>\n",
              "      <th>1.06456613243598</th>\n",
              "      <th>...</th>\n",
              "      <th>-0.449804627263864</th>\n",
              "      <th>-1.27888499555974</th>\n",
              "      <th>0.019728921381961</th>\n",
              "      <th>-0.525997185720502</th>\n",
              "      <th>0.561247041848369</th>\n",
              "      <th>-0.845993246118688</th>\n",
              "      <th>0.0125287619204441</th>\n",
              "      <th>0.00912469017906386</th>\n",
              "      <th>1.62</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34714.0</td>\n",
              "      <td>-0.505623</td>\n",
              "      <td>0.696249</td>\n",
              "      <td>0.864695</td>\n",
              "      <td>1.120677</td>\n",
              "      <td>0.042565</td>\n",
              "      <td>-0.077980</td>\n",
              "      <td>0.948634</td>\n",
              "      <td>-0.118641</td>\n",
              "      <td>-0.296673</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054431</td>\n",
              "      <td>0.398556</td>\n",
              "      <td>0.037060</td>\n",
              "      <td>0.175790</td>\n",
              "      <td>-0.386621</td>\n",
              "      <td>-0.328350</td>\n",
              "      <td>-0.046589</td>\n",
              "      <td>-0.075340</td>\n",
              "      <td>81.40</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>34714.0</td>\n",
              "      <td>-1.347241</td>\n",
              "      <td>1.278883</td>\n",
              "      <td>1.380049</td>\n",
              "      <td>0.913509</td>\n",
              "      <td>0.162013</td>\n",
              "      <td>-0.114490</td>\n",
              "      <td>0.916754</td>\n",
              "      <td>-0.141199</td>\n",
              "      <td>-0.537024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002815</td>\n",
              "      <td>0.415186</td>\n",
              "      <td>-0.456130</td>\n",
              "      <td>0.137008</td>\n",
              "      <td>0.504979</td>\n",
              "      <td>-0.115927</td>\n",
              "      <td>0.314052</td>\n",
              "      <td>0.158906</td>\n",
              "      <td>88.23</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34715.0</td>\n",
              "      <td>-1.997486</td>\n",
              "      <td>-6.247751</td>\n",
              "      <td>-2.146480</td>\n",
              "      <td>0.828500</td>\n",
              "      <td>-2.484162</td>\n",
              "      <td>-0.205025</td>\n",
              "      <td>2.006526</td>\n",
              "      <td>-0.658223</td>\n",
              "      <td>-0.743316</td>\n",
              "      <td>...</td>\n",
              "      <td>1.187403</td>\n",
              "      <td>-0.648449</td>\n",
              "      <td>-1.788212</td>\n",
              "      <td>-0.005568</td>\n",
              "      <td>0.155405</td>\n",
              "      <td>-0.220592</td>\n",
              "      <td>-0.356211</td>\n",
              "      <td>0.307654</td>\n",
              "      <td>1800.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34715.0</td>\n",
              "      <td>-0.373098</td>\n",
              "      <td>1.153177</td>\n",
              "      <td>1.436122</td>\n",
              "      <td>0.138901</td>\n",
              "      <td>-0.096129</td>\n",
              "      <td>-1.163653</td>\n",
              "      <td>0.746219</td>\n",
              "      <td>-0.115367</td>\n",
              "      <td>-0.474063</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.236107</td>\n",
              "      <td>-0.599251</td>\n",
              "      <td>0.027593</td>\n",
              "      <td>0.670301</td>\n",
              "      <td>-0.190295</td>\n",
              "      <td>0.050345</td>\n",
              "      <td>0.247474</td>\n",
              "      <td>0.102719</td>\n",
              "      <td>5.36</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>34716.0</td>\n",
              "      <td>-0.338448</td>\n",
              "      <td>-0.012549</td>\n",
              "      <td>1.548567</td>\n",
              "      <td>-2.132899</td>\n",
              "      <td>0.332593</td>\n",
              "      <td>0.183520</td>\n",
              "      <td>0.186680</td>\n",
              "      <td>0.020768</td>\n",
              "      <td>-1.327153</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020604</td>\n",
              "      <td>-0.109244</td>\n",
              "      <td>-0.133021</td>\n",
              "      <td>-0.856017</td>\n",
              "      <td>-0.334356</td>\n",
              "      <td>-0.628094</td>\n",
              "      <td>-0.057004</td>\n",
              "      <td>-0.117696</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5fe9e93-b14d-453f-9acf-cc62ee5425fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5fe9e93-b14d-453f-9acf-cc62ee5425fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5fe9e93-b14d-453f-9acf-cc62ee5425fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(['Class']).count()"
      ],
      "metadata": {
        "id": "mCVOZYttEIl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Engineering**\n",
        "\n",
        "The Time column is ignored and the Amount is normalized. All other columns remain the same."
      ],
      "metadata": {
        "id": "_unNOZqhEOM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['Time'], axis=1)\n",
        "data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "GnjnBgwyEQOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(data, test_size=0.2, random_state=0)\n",
        "X_train = X_train.drop(['Class'], axis=1)\n",
        "y_test = X_test['Class']\n",
        "X_test = X_test.drop(['Class'], axis=1)\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "22RGCsKREShV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autoencoder Model**\n",
        "\n",
        "This is a standard dense autoencoder with four layers."
      ],
      "metadata": {
        "id": "LSByn_HdEXrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 14\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(encoding_dim, activation=\"tanh\", input_shape=(input_dim,)))\n",
        "model.add(Dense(int(encoding_dim / 2), activation=\"relu\"))\n",
        "model.add(Dense(int(encoding_dim / 2), activation='tanh'))\n",
        "model.add(Dense(input_dim, activation='relu'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW74eu4kEUx4",
        "outputId": "00a0b530-848d-4942-dff2-80498a7370fe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 14)                448       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 105       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 31)                248       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 857\n",
            "Trainable params: 857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Training**\n",
        "\n",
        "Given such a simple model and relatively small data set, it might be faster to train without a GPU."
      ],
      "metadata": {
        "id": "pCbsE2tBEdpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epoch = 40\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['acc'])\n",
        "\n",
        "history = model.fit(X_train, X_train,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(X_test, X_test),\n",
        "                    verbose=1)\n",
        "\n",
        "autoencoder = model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnbHg82jEjZb",
        "outputId": "759f6667-718e-46af-ff74-b7c8bac314dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 55443604.0000 - acc: 0.9813 - val_loss: 55516900.0000 - val_acc: 1.0000\n",
            "Epoch 2/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55426852.0000 - acc: 1.0000 - val_loss: 55500676.0000 - val_acc: 1.0000\n",
            "Epoch 3/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55410692.0000 - acc: 1.0000 - val_loss: 55484624.0000 - val_acc: 1.0000\n",
            "Epoch 4/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55394736.0000 - acc: 1.0000 - val_loss: 55468628.0000 - val_acc: 1.0000\n",
            "Epoch 5/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55378744.0000 - acc: 1.0000 - val_loss: 55452640.0000 - val_acc: 1.0000\n",
            "Epoch 6/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55362804.0000 - acc: 1.0000 - val_loss: 55436644.0000 - val_acc: 1.0000\n",
            "Epoch 7/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55346768.0000 - acc: 1.0000 - val_loss: 55420660.0000 - val_acc: 1.0000\n",
            "Epoch 8/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55330816.0000 - acc: 1.0000 - val_loss: 55404692.0000 - val_acc: 1.0000\n",
            "Epoch 9/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55314856.0000 - acc: 1.0000 - val_loss: 55388740.0000 - val_acc: 1.0000\n",
            "Epoch 10/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55298920.0000 - acc: 1.0000 - val_loss: 55372744.0000 - val_acc: 1.0000\n",
            "Epoch 11/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55282916.0000 - acc: 1.0000 - val_loss: 55356780.0000 - val_acc: 1.0000\n",
            "Epoch 12/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55267016.0000 - acc: 1.0000 - val_loss: 55340820.0000 - val_acc: 1.0000\n",
            "Epoch 13/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55251060.0000 - acc: 1.0000 - val_loss: 55324848.0000 - val_acc: 1.0000\n",
            "Epoch 14/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55235132.0000 - acc: 1.0000 - val_loss: 55308920.0000 - val_acc: 1.0000\n",
            "Epoch 15/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55219164.0000 - acc: 1.0000 - val_loss: 55292932.0000 - val_acc: 1.0000\n",
            "Epoch 16/40\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 55203260.0000 - acc: 1.0000 - val_loss: 55277004.0000 - val_acc: 1.0000\n",
            "Epoch 17/40\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 55187296.0000 - acc: 1.0000 - val_loss: 55261052.0000 - val_acc: 1.0000\n",
            "Epoch 18/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55171368.0000 - acc: 1.0000 - val_loss: 55245080.0000 - val_acc: 1.0000\n",
            "Epoch 19/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55155408.0000 - acc: 1.0000 - val_loss: 55229148.0000 - val_acc: 1.0000\n",
            "Epoch 20/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55139496.0000 - acc: 1.0000 - val_loss: 55213212.0000 - val_acc: 1.0000\n",
            "Epoch 21/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55123524.0000 - acc: 1.0000 - val_loss: 55197260.0000 - val_acc: 1.0000\n",
            "Epoch 22/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55107604.0000 - acc: 1.0000 - val_loss: 55181296.0000 - val_acc: 1.0000\n",
            "Epoch 23/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55091708.0000 - acc: 1.0000 - val_loss: 55165420.0000 - val_acc: 1.0000\n",
            "Epoch 24/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55075776.0000 - acc: 1.0000 - val_loss: 55149456.0000 - val_acc: 1.0000\n",
            "Epoch 25/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55059864.0000 - acc: 1.0000 - val_loss: 55133504.0000 - val_acc: 1.0000\n",
            "Epoch 26/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55043972.0000 - acc: 1.0000 - val_loss: 55117604.0000 - val_acc: 1.0000\n",
            "Epoch 27/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55027996.0000 - acc: 1.0000 - val_loss: 55101692.0000 - val_acc: 1.0000\n",
            "Epoch 28/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 55012116.0000 - acc: 1.0000 - val_loss: 55085748.0000 - val_acc: 1.0000\n",
            "Epoch 29/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54996180.0000 - acc: 1.0000 - val_loss: 55069824.0000 - val_acc: 1.0000\n",
            "Epoch 30/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54980284.0000 - acc: 1.0000 - val_loss: 55053888.0000 - val_acc: 1.0000\n",
            "Epoch 31/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54964392.0000 - acc: 1.0000 - val_loss: 55037996.0000 - val_acc: 1.0000\n",
            "Epoch 32/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54948496.0000 - acc: 1.0000 - val_loss: 55022060.0000 - val_acc: 1.0000\n",
            "Epoch 33/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54932580.0000 - acc: 1.0000 - val_loss: 55006140.0000 - val_acc: 1.0000\n",
            "Epoch 34/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54916652.0000 - acc: 1.0000 - val_loss: 54990252.0000 - val_acc: 1.0000\n",
            "Epoch 35/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54900812.0000 - acc: 1.0000 - val_loss: 54974332.0000 - val_acc: 1.0000\n",
            "Epoch 36/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54884828.0000 - acc: 1.0000 - val_loss: 54958412.0000 - val_acc: 1.0000\n",
            "Epoch 37/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54869000.0000 - acc: 1.0000 - val_loss: 54942536.0000 - val_acc: 1.0000\n",
            "Epoch 38/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54853076.0000 - acc: 1.0000 - val_loss: 54926600.0000 - val_acc: 1.0000\n",
            "Epoch 39/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54837232.0000 - acc: 1.0000 - val_loss: 54910708.0000 - val_acc: 1.0000\n",
            "Epoch 40/40\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 54821324.0000 - acc: 1.0000 - val_loss: 54894800.0000 - val_acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Performance**\n",
        "\n",
        "A simple plot of model accuracy to confirm that it is learning something."
      ],
      "metadata": {
        "id": "BYhqHNIoEqDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "hJVYnZcnEpRd",
        "outputId": "93915299-ec70-48f4-ccc1-945781a436c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbxVZZ338c+Xw+HBRElAM46BJpWYCEqWNgXaWPiIWibcWVo2ZqM9TGMqOWOOM47ZWDakU7cVqY2lRZlYmBrCDb7UFBUQMhTN4iDqkQREzuE8/e4/1rVhcdjA4Zy92Qf29/167RdrXWtda/3WUvaP67rWXpciAjMzs1LoVekAzMxs9+GkYmZmJeOkYmZmJeOkYmZmJeOkYmZmJeOkYmZmJeOkYtYFkoZLCkm9O7HvuZIe3BlxmVWak4rt9iS9IKlZ0uAO5U+mxDC8MpGZ7X6cVKxa/BmYXFiRdBiwR+XC6Rk609Iy2xFOKlYtfgJ8Krd+DnBrfgdJe0u6VVKDpL9I+hdJvdK2GknXSXpV0vPASUXq/kjSSkkrJP2HpJrOBCbpF5JekrRG0lxJh+a29Zf0rRTPGkkPSuqftv2dpIckrZa0XNK5qXyOpM/mjrFZ91tqnV0o6Vng2VT23+kYayU9LukDuf1rJH1N0nOSXk/bD5B0o6RvdbiWGZL+qTPXbbsnJxWrFo8Ae0k6JH3ZTwL+t8M+3wX2Bg4CxpEloU+nbf8AnAyMAcYCH+tQ92agFTg47fNh4LN0zj3ACGBf4Angtty264AjgWOAfYBLgHZJw1K97wJDgNHAgk6eD+A04L3AyLT+WDrGPsBPgV9I6pe2fYWslXcisBfwGWA9cAswOZd4BwN/n+pbtYoIf/zZrT/AC2Rfdv8CXANMAO4HegMBDAdqgGZgZK7e54A5afkB4ILctg+nur2B/YANQP/c9snA7LR8LvBgJ2MdmI67N9k/+hqBw4vsNwW4cyvHmAN8Nre+2fnT8Y/bThyvFc4LLAUmbmW/p4Hj0/JFwMxK//f2p7If96daNfkJMBc4kA5dX8BgoBb4S67sL8DQtPxWYHmHbQXDUt2VkgplvTrsX1RqNV0NnEnW4mjPxdMX6Ac8V6TqAVsp76zNYpN0MXAe2XUGWYuk8GDDts51C3A2WZI+G/jvbsRkuwF3f1nViIi/kA3Ynwj8qsPmV4EWsgRR8DZgRVpeSfblmt9WsJyspTI4Igamz14RcSjb93+AiWQtqb3JWk0ASjE1AW8vUm/5VsoB3mDzhxDeUmSfja8nT+MnlwAfB94cEQOBNSmG7Z3rf4GJkg4HDgF+vZX9rEo4qVi1OY+s6+eNfGFEtAE/B66WNCCNWXyFTeMuPwe+KKlO0puBy3J1VwL3Ad+StJekXpLeLmlcJ+IZQJaQVpElgv/MHbcdmAZ8W9Jb04D50ZL6ko27/L2kj0vqLWmQpNGp6gLgDEl7SDo4XfP2YmgFGoDekq4ga6kU/BD4d0kjlBklaVCKsZ5sPOYnwC8jorET12y7MScVqyoR8VxEzN/K5i+Q/Sv/eeBBsgHnaWnbD4B7gYVkg+kdWzqfAvoAfyQbj5gO7N+JkG4l60pbkeo+0mH7xcBTZF/cfwOuBXpFxF/JWlz/nMoXAIenOteTjQ+9TNY9dRvbdi/wO+CZFEsTm3ePfZssqd4HrAV+BPTPbb8FOIwssViVU4Qn6TKzrpP0QbIW3bDwF0rVc0vFzLpMUi3wJeCHTigGTipm1kWSDgFWk3XzfafC4VgP4e4vMzMrGbdUzMysZKr6x4+DBw+O4cOHVzoMM7NdyuOPP/5qRAwptq2qk8rw4cOZP39rT5eamVkxkv6ytW3u/jIzs5JxUjEzs5JxUjEzs5Kp6jGVYlpaWqivr6epqanSoZRdv379qKuro7a2ttKhmNluwkmlg/r6egYMGMDw4cPJvcZ8txMRrFq1ivr6eg488MBKh2Nmu4mydn9JmibpFUmLt7JdkqZKWiZpkaQjctvOkfRs+pyTKz9S0lOpzlSlb35J+0i6P+1/f3qT7A5rampi0KBBu3VCAZDEoEGDqqJFZmY7T7nHVG4mm2Vva04gm0Z1BHA+8D3IEgTwdbLpTo8Cvp5LEt8jm9q1UK9w/MuAWRExAphF7tXkO2p3TygF1XKdZrbzlLX7KyLmShq+jV0mAremF9E9ImmgpP2B8cD9EfE3AEn3AxMkzQH2iohHUvmtZHNt35OONT4d9xayKVUvLe0VJWvqoWXr00a0R9Datmu8/qZ17css//Y/VjoMM9vJtP8o6iaXfqLOSo+pDGXzeRvqU9m2yuuLlAPslyZLAniJbN7wLUg6n6xVxNve9rZiu3RbS1vQ0ta+/R2LWPXaak4569MAvNzwKjW9ahg8KGukzfnNHfTp02erdZ9YuJifTb+L//r3yzt9vrb2dlas9rxKZtWm9x6N1JXjuGU4ZsVFREgq2lSIiJuAmwDGjh3btebE3tv+T/Hqa42saWxh5Fv32uZ+xew5FBYt+RMAV155JXvuuScXX3zxxu2tra307l38P9sHhx7CB088c4fO13ctjL6q47xQZmZdU+nfqaxg83m/61LZtsrripQDvJy6zkh/vlKmmLerPYJeJRyuOPfcc7ngggt473vfyyWXXMKjjz7K0UcfzZgxYzjmmGNYunQpAHPmzOHkk08GsoT0mc98hvHjx3PQQQcxderU0gVkZrYVlW6pzAAuknQ72aD8mohYKele4D9zg/MfBqZExN8krZX0PuAPZFO4fjd3rHOAb6Q/7+pucP929xL++OLaHa63obWN9nbo36dmi20j37oXXz/l0B0+Zn19PQ899BA1NTWsXbuWefPm0bt3b37/+9/zta99jV/+8pdb1PnTn/7E7Nmzef3113nnO9/J5z//ef8mxczKqqxJRdLPyAbPB0uqJ3uiqxYgIr4PzCSbZ3sZsB74dNr2N0n/TjYvN8BVhUF74B/JnirrTzZAf08q/wbwc0nnkc2z/fFyXtu2RAAlfrDqzDPPpKYmS1Jr1qzhnHPO4dlnn0USLS0tReucdNJJ9O3bl759+7Lvvvvy8ssvU1dXjl5UM7NMuZ/+mryd7QFcuJVt04BpRcrnA+8uUr4K+FDXIi2uKy0KgOcb1hEBb993z5LF8qY3vWnj8r/+679y7LHHcuedd/LCCy8wfvz4onX69u27cbmmpobW1taSxWNmVkylx1R2S+0B5fwJyJo1axg6NHvo7eabby7ficzMdpCTShlkA/XlyyqXXHIJU6ZMYcyYMW59mFmPUtVz1I8dOzY6TtL19NNPc8ghh3TruEtfWkv/Pr152z57dOs4O0MprtfMqoukxyNibLFtbqmUQXtQ0keKzcx2FU4qZVDu7i8zs57KSaUM3FIxs2rlpFJi7RFEhN8AbGZVyUmlxAoPPrj7y8yqkZNKibWnh+nc/WVm1ajS7/7a7bR3s6WyatUqPvSh7MUAL730EjU1NQwZMgSARx99dJuvvofspZJ9+vThmGOO6dL5zcy6w0mlxKKbLZVBgwaxYMECoPir77dnzpw57Lnnnk4qZlYR7v4qsUJLpZQD9Y8//jjjxo3jyCOP5CMf+QgrV2ZzkU2dOpWRI0cyatQoJk2axAsvvMD3v/99rr/+ekaPHs28efNKFoOZWWe4pbIt91wGLz21Q1X6tgcHtbTRv7ameHPlLYfBCd/o9PEigi984QvcddddDBkyhDvuuIPLL7+cadOm8Y1vfIM///nP9O3bl9WrVzNw4EAuuOCCHW7dmJmVipNKiQWp/6tEDZUNGzawePFijj/+eADa2trYf//9ARg1ahSf+MQnOO200zjttNNKc0Izs25wUtmWHWhRFKxb38xf/7aed+w3gJraLSfp2lERwaGHHsrDDz+8xbbf/va3zJ07l7vvvpurr76ap57asVaVmVmpeUylxEr9SHHfvn1paGjYmFRaWlpYsmQJ7e3tLF++nGOPPZZrr72WNWvWsG7dOgYMGMDrr79empObme0gJ5USixIP1Pfq1Yvp06dz6aWXcvjhhzN69Ggeeugh2traOPvssznssMMYM2YMX/ziFxk4cCCnnHIKd955pwfqzawi3P1VYptaKt1PKldeeeXG5blz526x/cEHH9yi7B3veAeLFi3q9rnNzLqirC0VSRMkLZW0TNJlRbYPkzRL0iJJcyTV5bZdK2lx+pyVK58naUH6vCjp16l8vKQ1uW1XlPPatmbTjx8rcXYzs8oqW0tFUg1wI3A8UA88JmlGRPwxt9t1wK0RcYuk44BrgE9KOgk4AhgN9AXmSLonItZGxAdy5/glcFfuePMi4uRyXVNntKeXSfqFkmZWjcrZUjkKWBYRz0dEM3A7MLHDPiOBB9Ly7Nz2kcDciGiNiDeARcCEfEVJewHHAb8udeDdmQ0zdqHX3lfzrJ9mVh7lTCpDgeW59fpUlrcQOCMtnw4MkDQolU+QtIekwcCxwAEd6p4GzIqItbmyoyUtlHSPpEOLBSXpfEnzJc1vaGjYYnu/fv1YtWpVl79wd5UJuiKCVatW0a9fv0qHYma7kUoP1F8M3CDpXGAusAJoi4j7JL0HeAhoAB4G2jrUnQz8MLf+BDAsItZJOpGsBTOi4wkj4ibgJsjmqO+4va6ujvr6eoolnM742xvNNLe2w+qe/2Xdr18/6urqtr+jmVknlTOprGDz1kVdKtsoIl4ktVQk7Ql8NCJWp21XA1enbT8FninUS62Xo8haN4Vjrc0tz5T0P5IGR8SrOxJ0bW0tBx544I5U2cz5t85n+WuN3POlMV0+hpnZrqqc3V+PASMkHSipDzAJmJHfQdJgSYUYpgDTUnlN6gZD0ihgFHBfrurHgN9ERFPuWG9RGh2XdBTZta0qy5VtQ2NLG/1r/fMfM6tOZWupRESrpIuAe4EaYFpELJF0FTA/ImYA44FrJAVZ99eFqXotMC/liLXA2RHRmjv8JKDjO1Q+BnxeUivQCEyKCoxENza30b9P91/PYma2KyrrmEpEzARmdii7Irc8HZhepF4T2RNgWzvu+CJlNwA3dCPckmhsaWPgHrWVDsPMrCLcT1NijS1t9CvBiyTNzHZFTiol1tSc5lIxM6tCTiol1tjiMRUzq15OKiXW2OKWiplVLyeVEmpvD5pa2j2mYmZVy0mlhDa0tgOwh7u/zKxKOamU0Prm7Kc0HlMxs2rlpFJCjS3Z68nc/WVm1cpJpYSaUlLxQL2ZVSsnlRJqbM7GVJxUzKxaOamUUKH7y2MqZlatnFRKyGMqZlbtnFRKqLHZYypmVt2cVEqoyd1fZlblnFRKqNFPf5lZlXNSKaGN3V9uqZhZlXJSKSG3VMys2pU1qUiaIGmppGWSLiuyfZikWZIWSZojqS637VpJi9PnrFz5zZL+LGlB+oxO5ZI0NZ1rkaQjynltxTQ2t1HTS9TWaGef2sysRyhbUpFUA9wInEA2NfBkSR2nCL4OuDUiRgFXAdekuicBRwCjgfcCF0vaK1fvqxExOn0WpLITgBHpcz7wvfJc2dYVXnsvOamYWXUqZ0vlKGBZRDwfEc3A7cDEDvuMBB5Iy7Nz20cCcyOiNSLeABYBE7ZzvolkCSoi4hFgoKT9S3EhneWphM2s2pUzqQwFlufW61NZ3kLgjLR8OjBA0qBUPkHSHpIGA8cCB+TqXZ26uK6X1HcHzoek8yXNlzS/oaGhq9dWVFNzG/37eJjKzKpXpb8BLwbGSXoSGAesANoi4j5gJvAQ8DPgYaAt1ZkCvAt4D7APcOmOnDAiboqIsRExdsiQIaW5isSzPppZtStnUlnB5q2LulS2UUS8GBFnRMQY4PJUtjr9eXUaMzkeEPBMKl+Zurg2AD8m62br1PnKzUnFzKpdOZPKY8AISQdK6gNMAmbkd5A0WFIhhinAtFRek7rBkDQKGAXcl9b3T38KOA1YnOrPAD6VngJ7H7AmIlaW8fq20NjsMRUzq269y3XgiGiVdBFwL1ADTIuIJZKuAuZHxAxgPHCNpADmAhem6rXAvPQU1Vrg7IhoTdtukzSErPWyALgglc8ETgSWAeuBT5fr2ramqaWNfd7UZ2ef1sysxyhbUgGIiJlkX/b5sityy9OB6UXqNZE9AVbsmMdtpTzYlJQqYn1zG0Pf7JaKmVWvSg/U71b8SLGZVTsnlRJq8kC9mVU5J5USamx2UjGz6uakUiIRkT1S7DcUm1kVc1Ipkea2dtrDUwmbWXVzUimRpuZ2wK+9N7Pq5qRSIo2eStjMzEmlVDxBl5mZk0rJeCphMzMnlZJpbMneIuOWiplVMyeVEmksDNS7pWJmVcxJpUQ8pmJm5qRSMoWk4t+pmFk1c1IpkSYP1JuZOamUiru/zMycVErGScXMzEmlZAq/U+nb27fUzKqXvwFLpDCXSq9eqnQoZmYVU9akImmCpKWSlkm6rMj2YZJmSVokaY6kuty2ayUtTp+zcuW3pWMuljRNUm0qHy9pjaQF6XNFx/OVk197b2ZWxqQiqQa4ETiBbL75yZI6zjt/HXBrRIwCrgKuSXVPAo4ARgPvBS6WtFeqcxvwLuAwoD/w2dzx5kXE6PS5qjxXVtx6T9BlZrb9pCLpFEldST5HAcsi4vmIaAZuByZ22Gck8EBanp3bPhKYGxGtEfEGsAiYABARMyMBHgXq6AGy+endm2hm1a0z34JnAc9K+qakd+3AsYcCy3Pr9aksbyFwRlo+HRggaVAqnyBpD0mDgWOBA/IVU7fXJ4Hf5YqPlrRQ0j2SDi0WlKTzJc2XNL+hoWEHLmfbmprd/WVmtt2kEhFnA2OA54CbJT2cvpgHlOD8FwPjJD0JjANWAG0RcR8wE3gI+BnwMNDWoe7/kLVm5qX1J4BhEXE48F3g11u5npsiYmxEjB0yZEgJLiHT2OLuLzOzTvXXRMRaYDpZF9b+ZK2KJyR9YRvVVrB566IuleWP+2JEnBERY4DLU9nq9OfVaWzkeEDAM4V6kr4ODAG+ko8xItal5ZlAbWrl7BRZ95eTiplVt86MqZwq6U5gDlALHBURJwCHA/+8jaqPASMkHSipDzAJmNHh2INz4zVTgGmpvCZ1gyFpFDAKuC+tfxb4CDA5Itpzx3qLJKXlo9K1rdre9ZVKowfqzczo3Yl9PgpcHxFz84URsV7SeVurFBGtki4C7gVqgGkRsUTSVcD8iJgBjAeukRTAXODCVL0WmJdyxFrg7IhoTdu+D/wFeDht/1V60utjwOcltQKNwKQ0mL9TNPmRYjOzTiWVK4GVhRVJ/YH9IuKFiJi1rYqpG2pmh7IrcsvTybrVOtZrInsCrNgxi8YcETcAN2wrnnLymIqZWefGVH4BtOfW21KZ5TT66S8zs04lld7pdyYApOU+5Qtp1+SWiplZ55JKg6RTCyuSJgKvli+kXU9LWzstbeGkYmZVrzNjKhcAt0m6gezR3uXAp8oa1S6mqcUTdJmZQSeSSkQ8B7xP0p5pfV3Zo9rFeCphM7NMZ1oqhRc8Hgr0S4/xsrNf2NiTNTVnzzG4+8vMql1nfvz4fbL3f32BrPvrTGBYmePapTS6+8vMDOjcQP0xEfEp4LWI+DfgaOAd5Q1r1+KphM3MMp1JKk3pz/WS3gq0kL3/y5LCVMIeUzGzateZMZW7JQ0E/ovsTcAB/KCsUe1iCk9/7eHuLzOrcttMKullj7PSm4N/Kek3QL+IWLNTottFeEzFzCyzze6v9BbgG3PrG5xQtrS+2WMqZmbQuTGVWZI+WnitvG3Jv1MxM8t0Jql8juwFkhskrZX0uqS1ZY5rl9LU7O4vMzPo3C/qSzFt8G5tY0uld6cm0jQz221tN6lI+mCx8o6TdlWzxpY2+tT0oneNk4qZVbfOPFL81dxyP+Ao4HHguLJEtAtqbG6jX60TipnZdr8JI+KU3Od44N3Aa505uKQJkpZKWibpsiLbh0maJWmRpDmS6nLbrpW0OH3OypUfKOkP6Zh3SOqTyvum9WVp+/DOxFgKnkrYzCzTlX9e1wOHbG8nSTVkjyOfQDY18GRJHacIvg64NSJGAVcB16S6JwFHAKOB9wIXS9or1bkWuD4iDiZLbuel8vPIXiVzMHB92m+naGxpY48+nXo3p5nZbq0zL5T8rqSp6XMDMI/sl/XbcxSwLCKeT7NF3g5M7LDPSOCBtDw7t30kMDciWiPiDWARMCE91nwcm+a1vwU4LS1PTOuk7R/aWY9BZ91fbqmYmXWmpTKfbAzlceBh4NKIOLsT9YaSTehVUJ/K8hYCZ6Tl04EBkgal8gmS9pA0GDgWOAAYBKyOiNYix9x4vrR9Tdp/M5LOlzRf0vyGhoZOXMb2ZVMJe0zFzKwzfTbTgaaIaIOsW0vSHhGxvgTnvxi4QdK5wFxgBdAWEfdJeg/wENBAlszaSnA+IuIm4CaAsWPHRimO2djsMRUzM+jkL+qB/rn1/sDvO1FvBVnroqAulW0UES9GxBkRMQa4PJWtTn9eHRGj08MBAp4BVgEDJfUucsyN50vb9077l13WUnFSMTPrTFLpl59COC3v0Yl6jwEj0tNafYBJwIz8DpIGp5dWAkwBpqXymtQNhqRRwCjgvogIsrGXj6U65wB3peUZaZ20/YG0f9k1tnhMxcwMOpdU3pB0RGFF0pFA4/YqpXGNi4B7gaeBn0fEEklXSTo17TYeWCrpGWA/4OpUXgvMk/RHsq6qs3PjKJcCX5G0jGzM5Eep/EfAoFT+FWCLR5jLpanZLRUzM+jcmMqXgV9IepGsG+otZNMLb1dEzARmdii7Irc8nU1PcuX3aSJ7AqzYMZ8ne7KsWJ0zOxNXqTX6dypmZkDn3v31mKR3Ae9MRUsjoqW8Ye1aPKZiZpbpzO9ULgTeFBGLI2IxsKekfyx/aLuG9vagqaXdYypmZnRuTOUfCk9kAUTEa8A/lC+kXcuG1nbAUwmbmUHnkkpN/pfp6fUrfcoX0q7FUwmbmW3SmYH63wF3SPq/af1zwD3lC2nXsr45eyjN3V9mZp1LKpcC5wMXpPVFZE+AGdkbisHz05uZQedefd8O/AF4gexR3uPIfndiQGNzNqbipGJmto2WiqR3AJPT51XgDoCIOHbnhLZr8JiKmdkm2+r++hPZa+5PjohlAJL+aadEtQvZOD+9WypmZtvs/joDWAnMlvQDSR8i+0W95TQ2e0zFzKxgq0klIn4dEZOAd5G9xPHLwL6SvifpwzsrwJ6uyd1fZmYbdWag/o2I+GlEnEL2qvknyZ4IMzZ1f/nHj2ZmOzhHfUS8FhE3RcSHyhXQrqbQ/eUxFTOzHUwqtqVG/07FzGwjJ5Vuamxuo6aXqK3xMwxmZk4q3VR47X3u9WhmZlXLSaWbPJWwmdkmZU0qkiZIWippmaQtpveVNEzSLEmLJM2RVJfb9k1JSyQ9LWmqMgMkLch9XpX0nbT/uZIacts+W85rK2hqbqN/H+dmMzPo3AsluyS9Iv9G4HigHnhM0oyI+GNut+uAWyPiFknHAdcAn5R0DPB+YFTa70FgXETMAUbnzvE48Kvc8e6IiIvKdU3FeNZHM7NNyvlP7KOAZRHxfEQ0A7cDEzvsMxJ4IC3Pzm0PoB/ZvC19gVrg5XzF9G6yfcleJVMxTipmZpuUM6kMBZbn1utTWd5CstfBAJwODJA0KCIeJksyK9Pn3ojo+GbkSWQtk8iVfTR1pU2XdECpLmRbGps9pmJmVlDpwYCLgXGSngTGASuANkkHA4eQ/YJ/KHCcpA90qDsJ+Flu/W5geESMAu4Hbil2QknnS5ovaX5DQ0O3L6Cppc2/pjczS8qZVFYA+dZCXSrbKCJejIgzImIMcHkqW03WankkItZFxDqymSaPLtSTdDjQOyIezx1rVURsSKs/BI4sFlR6I8DYiBg7ZMiQbl9kY0ub3/tlZpaUM6k8BoyQdKCkPmQtixn5HSQNllSIYQowLS3/lawF01tSLVkrJt/9NZnNWylI2j+3eio7aSKx9e7+MjPbqGxPf0VEq6SLgHuBGmBaRCyRdBUwPyJmAOOBayQFMBe4MFWfTjbD5FNkg/a/i4i7c4f/OHBih1N+UdKpQCvwN+DcslxYB00eqDcz26hsSQUgImYCMzuUXZFbnk6WQDrWawM+t43jHlSkbApZa2enamx2UjEzK6j0QP0uLSI8pmJmluOk0g3Nbe20h197b2ZW4KTSDU3N7YBfe29mVuCk0g2NnkrYzGwzTird4KmEzcw256TSDZ5K2Mxsc04q3dDY0gp4TMXMrMBJpRsaCwP17v4yMwOcVLpl40C9WypmZoCTSrcUkorHVMzMMk4q3dDU7EeKzczynFS6wd1fZmabc1LpBicVM7PNOal0Q+F3Kn17+zaamYGTSrcU5lLp1UuVDsXMrEdwUukGv/bezGxzTirdsN4TdJmZbcZJpRsaW9roV+tbaGZWUNZvREkTJC2VtEzSZUW2D5M0S9IiSXMk1eW2fVPSEklPS5oqSal8TjrmgvTZN5X3lXRHOtcfJA0v57VB9jsVd3+ZmW1StqQiqQa4ETgBGAlMljSyw27XAbdGxCjgKuCaVPcY4P3AKODdwHuAcbl6n4iI0enzSio7D3gtIg4GrgeuLc+VbdLY4u4vM7O8crZUjgKWRcTzEdEM3A5M7LDPSOCBtDw7tz2AfkAfoC9QC7y8nfNNBG5Jy9OBDxVaN+WSdX85qZiZFZQzqQwFlufW61NZ3kLgjLR8OjBA0qCIeJgsyaxMn3sj4ulcvR+nrq9/zSWOjeeLiFZgDTCoY1CSzpc0X9L8hoaGbl1gowfqzcw2U+lR5ouBcZKeJOveWgG0SToYOASoI0sWx0n6QKrziYg4DPhA+nxyR04YETdFxNiIGDtkyJBuBd/kR4rNzDZTzqSyAjggt16XyjaKiBcj4oyIGANcnspWk7VaHomIdRGxDrgHODptX5H+fB34KVk322bnk9Qb2BtYVZ5LyzS2tHkqYTOznHImlceAEZIOlNQHmATMyO8gabCkQgxTgGlp+a9kLZjekmrJWjFPp/XBqW4tcDKwONWZAZyTlj8GPBARUaZrA7LuL4+pmJltUrakksY1LgLuBZ4Gfh4RSyRdJenUtNt4YKmkZ4D9gKtT+XTgOeApsnGXhRFxN27IAc0AAAneSURBVNmg/b2SFgELyFonP0h1fgQMkrQM+AqwxSPMpeanv8zMNte7nAePiJnAzA5lV+SWp5MlkI712oDPFSl/AzhyK+dqAs7sZsid1tLWTktbOKmYmeVUeqB+l9XU4gm6zMw6clLpIk8lbGa2JSeVLmpqbgc8QZeZWZ6TShc1uvvLzGwLTipd5KmEzcy25KTSRYWphN1SMTPbxEmli5rcUjEz24KTShd5TMXMbEtOKl20vtktFTOzjpxUusi/UzEz25KTShc1eaDezGwLTipdtLGl0tu30MyswN+IXdTY0kafml70rvEtNDMr8DdiF2Vzqfj2mZnl+VuxizyVsJnZlpxUuiibSris09GYme1ynFS6yFMJm5ltqaxJRdIESUslLZO0xfS+koZJmiVpkaQ5kupy274paYmkpyVNVWYPSb+V9Ke07Ru5/c+V1CBpQfp8tpzXlk0l7JxsZpZXtm9FSTXAjcAJwEhgsqSRHXa7Drg1IkYBVwHXpLrHAO8HRgHvBt4DjCvUiYh3AWOA90s6IXe8OyJidPr8sEyXBmQtFY+pmJltrpz/1D4KWBYRz0dEM3A7MLHDPiOBB9Ly7Nz2APoBfYC+QC3wckSsj4jZAOmYTwB1VEDWUnFSMTPLK2dSGQosz63Xp7K8hcAZafl0YICkQRHxMFmSWZk+90bE0/mKkgYCpwCzcsUfTV1p0yUdULpL2VJji8dUzMw6qvSgwMXAOElPknVvrQDaJB0MHELWChkKHCfpA4VKknoDPwOmRsTzqfhuYHjqSrsfuKXYCSWdL2m+pPkNDQ1dDryp2S0VM7OOyplUVgD51kJdKtsoIl6MiDMiYgxweSpbTdZqeSQi1kXEOuAe4Ohc1ZuAZyPiO7ljrYqIDWn1h8CRxYKKiJsiYmxEjB0yZEiXL67Rv1MxM9tCOZPKY8AISQdK6gNMAmbkd5A0WFIhhinAtLT8V7IWTG9JtWStmKdTnf8A9ga+3OFY++dWTy3sXy4eUzEz21LZkkpEtAIXAfeSfcH/PCKWSLpK0qlpt/HAUknPAPsBV6fy6cBzwFNk4y4LI+Lu9Mjx5WQD/E90eHT4i+kx44XAF4Fzy3Vt7e1BU0u7WypmZh2U9SfhETETmNmh7Irc8nSyBNKxXhvwuSLl9YC2cq4pZK2dstvQ2g54gi4zs44qPVC/S/JUwmZmxTmpdMH65lbAsz6amXXkpNIFTS2en97MrBgnlS5obPaYiplZMU4qXeAxFTOz4pxUumDj/PRuqZiZbcZJpQsamz2mYmZWjJNKFwwZ0IcTD3sL+7ypT6VDMTPrUTwfbhccOWwfjhy2T6XDMDPrcdxSMTOzknFSMTOzknFSMTOzknFSMTOzknFSMTOzknFSMTOzknFSMTOzknFSMTOzklFEVDqGipHUAPyli9UHA6+WMJxScmxd05Njg54dn2Prml01tmERMaTYhqpOKt0haX5EjK10HMU4tq7pybFBz47PsXXN7hibu7/MzKxknFTMzKxknFS67qZKB7ANjq1renJs0LPjc2xds9vF5jEVMzMrGbdUzMysZJxUzMysZJxUukDSBElLJS2TdFml48mT9IKkpyQtkDS/wrFMk/SKpMW5sn0k3S/p2fTnm3tQbFdKWpHu3QJJJ1YotgMkzZb0R0lLJH0plVf83m0jtorfO0n9JD0qaWGK7d9S+YGS/pD+vt4haadP2bqN2G6W9OfcfRu9s2PLxVgj6UlJv0nrXbpvTio7SFINcCNwAjASmCxpZGWj2sKxETG6Bzz/fjMwoUPZZcCsiBgBzErrlXAzW8YGcH26d6MjYuZOjqmgFfjniBgJvA+4MP0/1hPu3dZig8rfuw3AcRFxODAamCDpfcC1KbaDgdeA83pQbABfzd23BRWIreBLwNO59S7dNyeVHXcUsCwino+IZuB2YGKFY+qRImIu8LcOxROBW9LyLcBpOzWoZCux9QgRsTIinkjLr5P9RR9KD7h324it4iKzLq3Wpk8AxwHTU3ml7tvWYusRJNUBJwE/TOuii/fNSWXHDQWW59br6SF/qZIA7pP0uKTzKx1MEftFxMq0/BKwXyWDKeIiSYtS91hFuubyJA0HxgB/oIfduw6xQQ+4d6kLZwHwCnA/8BywOiJa0y4V+/vaMbaIKNy3q9N9u15S30rEBnwHuARoT+uD6OJ9c1LZ/fxdRBxB1j13oaQPVjqgrYnsefYe86814HvA28m6J1YC36pkMJL2BH4JfDki1ua3VfreFYmtR9y7iGiLiNFAHVmvwrsqEUcxHWOT9G5gClmM7wH2AS7d2XFJOhl4JSIeL8XxnFR23ArggNx6XSrrESJiRfrzFeBOsr9YPcnLkvYHSH++UuF4NoqIl9Nf/HbgB1Tw3kmqJfvSvi0ifpWKe8S9KxZbT7p3KZ7VwGzgaGCgpN5pU8X/vuZim5C6EyMiNgA/pjL37f3AqZJeIOvOPw74b7p435xUdtxjwIj0ZEQfYBIwo8IxASDpTZIGFJaBDwOLt11rp5sBnJOWzwHuqmAsmyl8YSenU6F7l/qzfwQ8HRHfzm2q+L3bWmw94d5JGiJpYFruDxxPNuYzG/hY2q1S961YbH/K/SNBZGMWO/2+RcSUiKiLiOFk32cPRMQn6Op9iwh/dvADnAg8Q9Zfe3ml48nFdRCwMH2WVDo24GdkXSEtZH2y55H11c4CngV+D+zTg2L7CfAUsIjsC3z/CsX2d2RdW4uABelzYk+4d9uIreL3DhgFPJliWAxckcoPAh4FlgG/APr2oNgeSPdtMfC/wJ6V+H8uF+d44DfduW9+TYuZmZWMu7/MzKxknFTMzKxknFTMzKxknFTMzKxknFTMzKxknFTMykhSW+4NtAtUwrdaSxqef8uyWU/Qe/u7mFk3NEb2ag6zquCWilkFKJv35pvK5r55VNLBqXy4pAfSCwZnSXpbKt9P0p1pPo6Fko5Jh6qR9IM0R8d96dfaZhXjpGJWXv07dH+dldu2JiIOA24ge0sswHeBWyJiFHAbMDWVTwX+X2TzcRxB9sYEgBHAjRFxKLAa+GiZr8dsm/yLerMykrQuIvYsUv4C2aRNz6cXNL4UEYMkvUr2ipOWVL4yIgZLagDqInvxYOEYw8leoT4irV8K1EbEf5T/ysyKc0vFrHJiK8s7YkNuuQ2Pk1qFOamYVc5ZuT8fTssPkb0pFuATwLy0PAv4PGyc7GnvnRWk2Y7wv2rMyqt/mu2v4HcRUXis+M2SFpG1Niansi8AP5b0VaAB+HQq/xJwk6TzyFoknyd7y7JZj+IxFbMKSGMqYyPi1UrHYlZK7v4yM7OScUvFzMxKxi0VMzMrGScVMzMrGScVMzMrGScVMzMrGScVMzMrmf8PyDOxUGhAzB8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**\n",
        "\n",
        "Predictions are made on the test set. The mean-squared error (MSE) is calculated between the test set and their predictions. If the MSE is high, it's a potential irregularity that might suggest fraud. It's not perfect, there will be false positives and false negatives."
      ],
      "metadata": {
        "id": "0LashOrlEwy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
        "error_df = pd.DataFrame({'reconstruction_error': mse, 'true_class': y_test})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "bH_Hg_tyE0hA",
        "outputId": "0dfd9b31-09aa-47ca-edc4-8fee0ef30dfb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8efa46e0dd83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0merror_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'reconstruction_error'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true_class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_df.head()"
      ],
      "metadata": {
        "id": "lpS6I0YBE2rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Reconstruction Error**\n",
        "\n",
        "The reconstruction error for each sample is plotted long with a color code indicating known fraud. Only 6000 samples are plotted, but the index is randomly sampled from the original set, so the X-axis shows almost the full range of indices."
      ],
      "metadata": {
        "id": "dHDSQqUZE1hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 6.0\n",
        "\n",
        "groups = error_df.groupby('true_class')\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "for name, group in groups:\n",
        "    ax.plot(group.index, group.reconstruction_error, marker='o', ms=2.0, linestyle='',\n",
        "            label = \"Fraud\" if name == 1 else \"Normal\",\n",
        "            color = \"red\" if name == 1 else \"blue\")\n",
        "ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"green\", zorder=100, label='Threshold')\n",
        "ax.legend()\n",
        "plt.title(\"Reconstruction error for different classes\")\n",
        "plt.ylabel(\"Reconstruction error\")\n",
        "plt.xlabel(\"Data point index\")\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "aS6r1qQQE-P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis**\n",
        "\n",
        "Given the known fraud transactions, we can determine the number of true/false positives and negatives. Ideally, there should be no false positives and false negatives, but this is an imperfect model. Let's see how well it does."
      ],
      "metadata": {
        "id": "uH9TeOtxFC4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal = error_df[error_df.true_class == 0]\n",
        "fraud = error_df[error_df.true_class == 1]\n",
        "\n",
        "print('Normal transactions: %d, fraud transactions: %d' % (len(normal), len(fraud)))"
      ],
      "metadata": {
        "id": "TIli_fshFGkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_positives = len(fraud[fraud.reconstruction_error >= threshold])\n",
        "false_positives = len(normal[normal.reconstruction_error >= threshold])\n",
        "\n",
        "true_negatives = len(normal[normal.reconstruction_error < threshold])\n",
        "false_negatives = len(fraud[fraud.reconstruction_error < threshold])\n",
        "\n",
        "print('True positives: %d, true negatives: %d' % (true_positives, true_negatives))\n",
        "print('False positives: %d, false negatives: %d' % (false_positives, false_negatives))"
      ],
      "metadata": {
        "id": "MIvYkiqPFKZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**\n",
        "\n",
        "The confusion matrix below shows the number of true/false positive/negatives. It's not perfect, but not too bad either."
      ],
      "metadata": {
        "id": "UqRxZXV5FMha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"Normal\", \"Fraud\"]\n",
        "\n",
        "y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]\n",
        "conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_matrix, xticklabels=labels, yticklabels=labels, annot=True, fmt=\"d\");\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.ylabel('True class')\n",
        "plt.xlabel('Predicted class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "50ndAGu7FL7E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}