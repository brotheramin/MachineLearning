{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcc44J1a40XAtxxip9xt2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brotheramin/MachineLearning/blob/main/SahandProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Roev_15KTPG",
        "outputId": "9a3add95-26a0-4a21-80c1-3aa6b6dbdd5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using failure column: HydroTest | RP positive rate in this column: 0.053\n",
            "[Info] RP rows used: 2794 | Fail rate: 0.053\n",
            "\n",
            "@ t=0.50: {'t': 0.5, 'pos_rate': 0.057245080500894455, 'acc': 0.9767441860465116, 'prec': 0.75, 'rec': 0.8275862068965517, 'f1': 0.7868852459016393, 'auc': np.float64(0.9469746258945998)}\n",
            "Confusion matrix:\n",
            " [[522   8]\n",
            " [  5  24]]\n",
            "\n",
            "@ t≈target 35%: {'t': 0.1, 'pos_rate': 0.2826475849731664, 'acc': 0.7620751341681574, 'prec': 0.17088607594936708, 'rec': 0.9310344827586207, 'f1': 0.2887700534759358, 'auc': np.float64(0.9469746258945998)}\n",
            "Confusion matrix:\n",
            " [[399 131]\n",
            " [  2  27]]\n",
            "\n",
            "Saved: RP_failure_classifier.pkl\n"
          ]
        }
      ],
      "source": [
        "# ==== RP Failure Classifier (auto-detect failure column, safe for single-class) ====\n",
        "import pandas as pd, numpy as np, joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "\n",
        "EXCEL_PATH = \"XF.xlsx\"\n",
        "SHEET_NAME = \"Sheet2\"\n",
        "TARGET_POSITIVE_RATE = 0.35        # you said ~35% RP segments fail\n",
        "USER_FAILURE_COL = None            # set to a specific column to skip auto-detect (e.g., \"HydroTest\")\n",
        "\n",
        "# --- version-safe OneHot ---\n",
        "def make_onehot():\n",
        "    try:    return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
        "    except TypeError:\n",
        "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=True)\n",
        "\n",
        "# --- helpers to map columns to binary ---\n",
        "POS_TOKENS = {\"fail\",\"failed\",\"ng\",\"reject\",\"leak\",\"leakage\",\"bad\",\"not pass\",\"nopass\",\"np\",\"no pass\"}\n",
        "NEG_TOKENS = {\"pass\",\"ok\",\"good\",\"normal\",\"success\"}\n",
        "\n",
        "def normalize_str_series(s: pd.Series) -> pd.Series:\n",
        "    return s.astype(str).str.strip().str.lower()\n",
        "\n",
        "def to_binary(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"Map a series to 0/1 if it looks like a failure flag. Return None if not mappable.\"\"\"\n",
        "    if np.issubdtype(series.dtype, np.number):\n",
        "        # numeric: treat >0 as fail\n",
        "        x = pd.to_numeric(series, errors=\"coerce\")\n",
        "        if x.notna().sum() == 0:\n",
        "            return None\n",
        "        # must be (mostly) binary-like\n",
        "        vals = set(np.unique(x.dropna()))\n",
        "        if vals.issubset({0,1}) or vals.issubset({0.0,1.0}) or len(vals) <= 3:\n",
        "            return (x.fillna(0) > 0).astype(int)\n",
        "        return None\n",
        "    # strings\n",
        "    xs = normalize_str_series(series)\n",
        "    uniq = set(xs.unique())\n",
        "    # direct binary case (two distinct values)\n",
        "    if len(uniq) == 2:\n",
        "        a,b = list(uniq)\n",
        "        # choose positive by token match\n",
        "        def has_pos(u):\n",
        "            return any(tok in u for tok in POS_TOKENS)\n",
        "        pos_val = a if has_pos(a) else (b if has_pos(b) else None)\n",
        "        if pos_val is not None:\n",
        "            return xs.eq(pos_val).astype(int)\n",
        "    # token-based mapping\n",
        "    pos_mask = xs.apply(lambda u: any(tok in u for tok in POS_TOKENS))\n",
        "    neg_mask = xs.apply(lambda u: any(tok in u for tok in NEG_TOKENS))\n",
        "    if pos_mask.any() or neg_mask.any():\n",
        "        return pos_mask.astype(int)\n",
        "    return None\n",
        "\n",
        "def auto_detect_failure_col(df_rp: pd.DataFrame, exclude_cols=None):\n",
        "    \"\"\"Scan columns right-to-left; pick the first that cleanly maps to binary with non-trivial positives.\"\"\"\n",
        "    if exclude_cols is None: exclude_cols = set()\n",
        "    candidates = []\n",
        "    for col in reversed(df_rp.columns.tolist()):\n",
        "        if col in exclude_cols:\n",
        "            continue\n",
        "        y_bin = to_binary(df_rp[col])\n",
        "        if y_bin is None:\n",
        "            continue\n",
        "        pos_rate = y_bin.mean()\n",
        "        # keep columns with 1%–99% positives\n",
        "        if 0.01 <= pos_rate <= 0.99:\n",
        "            # prioritize those close to your 35% expectation\n",
        "            score = abs(pos_rate - TARGET_POSITIVE_RATE)\n",
        "            candidates.append((score, -len(str(col)), col, pos_rate))  # tie-breakers: shorter name later\n",
        "    if candidates:\n",
        "        candidates.sort()\n",
        "        _,_,chosen, pr = candidates[0]\n",
        "        return chosen, pr\n",
        "    return None, None\n",
        "\n",
        "# --- load & light clean ---\n",
        "df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME)\n",
        "drop_unnamed = [c for c in df.columns if str(c).lower().startswith(\"unnamed\")]\n",
        "df = df.drop(columns=drop_unnamed, errors=\"ignore\")\n",
        "df = df.drop(columns=df.columns[df.isna().mean() > 0.70], errors=\"ignore\")\n",
        "for c in [\"Counter\",\"Weld NO.\"]:\n",
        "    if c in df.columns: df = df.drop(columns=[c])\n",
        "\n",
        "# --- RP filter (RESULT / RESULT2) ---\n",
        "def is_rp(s): return s.astype(str).str.strip().str.upper().isin([\"RP\",\"REPAIR\"])\n",
        "rp_mask = pd.Series(False, index=df.index)\n",
        "if \"RESULT\"  in df.columns:  rp_mask |= is_rp(df[\"RESULT\"])\n",
        "if \"RESULT2\" in df.columns:  rp_mask |= is_rp(df[\"RESULT2\"])\n",
        "df_rp = df.loc[rp_mask].copy()\n",
        "if df_rp.empty:\n",
        "    raise ValueError(\"No RP rows found in RESULT/RESULT2. Please check your dataset.\")\n",
        "\n",
        "# --- choose failure column ---\n",
        "exclude = {\"RESULT\",\"RESULT2\"}\n",
        "if USER_FAILURE_COL is not None and USER_FAILURE_COL in df_rp.columns:\n",
        "    failure_col = USER_FAILURE_COL\n",
        "    y_bin = to_binary(df_rp[failure_col])\n",
        "    pos_rate = float(y_bin.mean()) if y_bin is not None else 0.0\n",
        "    if (y_bin is None) or (pos_rate==0.0 or pos_rate==1.0):\n",
        "        # fallback to auto-detect if unusable\n",
        "        failure_col, pos_rate = auto_detect_failure_col(df_rp, exclude_cols=exclude)\n",
        "else:\n",
        "    failure_col, pos_rate = auto_detect_failure_col(df_rp, exclude_cols=exclude)\n",
        "\n",
        "# Final fallback: use the last column if still nothing\n",
        "if failure_col is None:\n",
        "    failure_col = df_rp.columns[-1]\n",
        "    y_bin = to_binary(df_rp[failure_col])\n",
        "    pos_rate = float(y_bin.mean()) if y_bin is not None else 0.0\n",
        "\n",
        "print(f\"Using failure column: {failure_col} | RP positive rate in this column: {pos_rate:.3f}\")\n",
        "\n",
        "# If still not binary-mappable or single-class, stop early with guidance\n",
        "y_bin = to_binary(df_rp[failure_col])\n",
        "if (y_bin is None) or (y_bin.nunique() < 2):\n",
        "    raise SystemExit(\n",
        "        \"Could not find a usable failure column with both classes in the RP subset.\\n\"\n",
        "        \"Tips:\\n\"\n",
        "        \"  1) Inspect the rightmost columns and any that mention 'fail', 'reject', 'leak', etc.\\n\"\n",
        "        \"  2) Set USER_FAILURE_COL = '<ExactColumnName>' above and re-run.\\n\"\n",
        "        \"  3) If the failure flag is numeric, ensure 1/0 or >0 implies failure.\\n\"\n",
        "    )\n",
        "\n",
        "# --- build X/y for RP subset ---\n",
        "mask = df_rp[failure_col].notna()\n",
        "X = df_rp.loc[mask].drop(columns=[failure_col]).copy()\n",
        "y = y_bin.loc[mask]\n",
        "\n",
        "cat = [c for c in X.columns if X[c].dtype == \"object\"]\n",
        "num = [c for c in X.columns if c not in cat]\n",
        "for c in cat: X[c] = X[c].astype(str)\n",
        "X = X[cat + num]\n",
        "\n",
        "# --- stratified split (guard if classes very rare) ---\n",
        "if y.nunique() < 2:\n",
        "    raise SystemExit(\"Target has only one class after NA filtering. Unable to train a classifier.\")\n",
        "\n",
        "try:\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "except ValueError:\n",
        "    # If class counts are tiny, fall back to unstratified split\n",
        "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "print(f\"[Info] RP rows used: {len(X)} | Fail rate: {y.mean():.3f}\")\n",
        "\n",
        "# --- pipeline & model ---\n",
        "pre = ColumnTransformer([\n",
        "    (\"num\", SimpleImputer(strategy=\"median\"), num),\n",
        "    (\"cat\", Pipeline([(\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                      (\"ohe\", make_onehot())]), cat),\n",
        "])\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=200, max_depth=20, min_samples_leaf=5, max_features=0.7,\n",
        "    class_weight=\"balanced\", n_jobs=-1, random_state=42\n",
        ")\n",
        "pipe = Pipeline([(\"preprocess\", pre), (\"clf\", clf)])\n",
        "pipe.fit(X_tr, y_tr)\n",
        "\n",
        "# --- evaluate (safe proba handling) ---\n",
        "def report(y_true, proba, t):\n",
        "    pred = (proba >= t).astype(int)\n",
        "    acc = accuracy_score(y_true, pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, pred, average=\"binary\", zero_division=0)\n",
        "    try: auc = roc_auc_score(y_true, proba)\n",
        "    except: auc = float(\"nan\")\n",
        "    cm = confusion_matrix(y_true, pred)\n",
        "    return dict(t=float(t), pos_rate=float(pred.mean()), acc=acc, prec=prec, rec=rec, f1=f1, auc=auc, cm=cm)\n",
        "\n",
        "# Predict probabilities if two classes exist; else back off to zeros\n",
        "if hasattr(pipe.named_steps[\"clf\"], \"classes_\") and len(pipe.named_steps[\"clf\"].classes_) == 2:\n",
        "    proba = pipe.predict_proba(X_te)[:, 1]\n",
        "else:\n",
        "    proba = np.zeros(len(X_te), dtype=float)  # degenerate (shouldn't happen after checks)\n",
        "\n",
        "r50 = report(y_te, proba, 0.50)\n",
        "print(\"\\n@ t=0.50:\", {k:r50[k] for k in [\"t\",\"pos_rate\",\"acc\",\"prec\",\"rec\",\"f1\",\"auc\"]})\n",
        "print(\"Confusion matrix:\\n\", r50[\"cm\"])\n",
        "\n",
        "# threshold to match ~35% positive rate\n",
        "cands = np.linspace(0.1, 0.9, 17)\n",
        "best, best_diff = None, 1.0\n",
        "for t in cands:\n",
        "    r = report(y_te, proba, t)\n",
        "    d = abs(r[\"pos_rate\"] - TARGET_POSITIVE_RATE)\n",
        "    if d < best_diff: best, best_diff = r, d\n",
        "\n",
        "print(\"\\n@ t≈target 35%:\", {k:best[k] for k in [\"t\",\"pos_rate\",\"acc\",\"prec\",\"rec\",\"f1\",\"auc\"]})\n",
        "print(\"Confusion matrix:\\n\", best[\"cm\"])\n",
        "\n",
        "# --- save model ---\n",
        "joblib.dump(pipe, \"RP_failure_classifier.pkl\")\n",
        "print(\"\\nSaved: RP_failure_classifier.pkl\")\n"
      ]
    }
  ]
}